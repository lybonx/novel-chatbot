import streamlit as st
import os

# --- 1. ê¸°ë³¸ ì„¤ì • ë° í™”ë©´ êµ¬ì„± ---
st.set_page_config(page_title="ì†Œì„¤ ìºë¦­í„° ì±—ë´‡", page_icon="ğŸ“š")
st.title("ğŸ“š ì†Œì„¤ ì† ìºë¦­í„°ì™€ ëŒ€í™”í•˜ê¸°")

# ë¡œë”© ìƒíƒœ í‘œì‹œë¥¼ ìœ„í•œ ê³µê°„
status_container = st.empty()

# --- 2. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ (ë¬´ê±°ìš´ ì‘ì—…) ---
if "imports_done" not in st.session_state:
    status_container.info("ğŸš€ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘... (AI ëª¨ë¸ ë¡œë”©)")

from operator import itemgetter
from langchain_openai import ChatOpenAI
from langchain_community.vectorstores import FAISS
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_community.chat_message_histories import ChatMessageHistory

st.session_state.imports_done = True
status_container.empty() # ë¡œë”© ë¬¸êµ¬ ì‚­ì œ


# --- 3. ì‚¬ì´ë“œë°” ì„¤ì • ---
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")
    
    # API í‚¤ ì…ë ¥
    api_key = st.text_input("OpenAI API Key", type="password")
    if api_key:
        os.environ["OPENAI_API_KEY"] = api_key
    
    # ëª¨ë¸ ì„ íƒ
    model_name = "gpt-3.5-turbo"
    # model_name = "ft:gpt-3.5-turbo:your-org:xxxx" # íŒŒì¸íŠœë‹ ëª¨ë¸ì´ ìˆë‹¤ë©´ ì£¼ì„ í•´ì œ
    
    st.divider()
    
    st.subheader("ğŸ­ ìºë¦­í„° ì„¤ì •")
    target_char = st.text_input("ìºë¦­í„° ì´ë¦„", value="ì…œë¡ í™ˆì¦ˆ")
    user_role = st.text_input("ë‹¹ì‹ ì˜ ì—­í• ", value="ë…ì")
    
    st.divider()
    
    if st.button("ğŸ—‘ï¸ ëŒ€í™” ë‚´ìš© ì´ˆê¸°í™”"):
        st.session_state.messages = []
        st.session_state.store = {}
        st.rerun()


# --- 4. ë°ì´í„°ë² ì´ìŠ¤(FAISS) ë¡œë“œ ---
@st.cache_resource
def load_db():
    DB_PATH = "./novel_db_faiss"
    
    if not os.path.exists(DB_PATH):
        return None
        
    embedding_function = HuggingFaceEmbeddings(
        model_name="sentence-transformers/all-MiniLM-L6-v2"
    )
    
    try:
        vectorstore = FAISS.load_local(
            DB_PATH, 
            embedding_function, 
            allow_dangerous_deserialization=True
        )
        return vectorstore.as_retriever(search_kwargs={"k": 3}) # ê´€ë ¨ ë‚´ìš© 3ê°œ ê²€ìƒ‰
    except Exception as e:
        return None

retriever = load_db()

# DBê°€ ì—†ì„ ê²½ìš° ê²½ê³ 
if not retriever:
    st.error("âŒ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
    st.warning("ğŸ‘‰ í”„ë¡œì íŠ¸ í´ë”ì— 'novel_db_faiss' í´ë”ê°€ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
    st.info("ğŸ’¡ í•´ê²°ë²•: í„°ë¯¸ë„ì—ì„œ 'python novel_ingest.py'ë¥¼ ì‹¤í–‰í•˜ì—¬ ì†Œì„¤ì„ ë¨¼ì € ì €ì¥í•´ì•¼ í•©ë‹ˆë‹¤.")
    st.stop()


# --- 5. ì²´ì¸ ìƒì„± í•¨ìˆ˜ ---
def get_rag_chain():
    llm = ChatOpenAI(model=model_name, temperature=0.7)

    # ì†Œì„¤ ë‚´ìš©ì„ ê°•ì œë¡œ ì°¸ê³ í•˜ë„ë¡ í”„ë¡¬í”„íŠ¸ ê°•í™”
    system_template = f"""
    ë‹¹ì‹ ì€ ì†Œì„¤ ì†ì— ë“±ì¥í•˜ëŠ” '{target_char}'ì…ë‹ˆë‹¤.
    í˜„ì¬ ë‹¹ì‹ ì€ '{user_role}'ì™€ ëŒ€í™”í•˜ê³  ìˆìŠµë‹ˆë‹¤.

    ì•„ë˜ [ì°¸ê³ í•œ ì†Œì„¤ ë‚´ìš©]ì„ ë°”íƒ•ìœ¼ë¡œ ëŒ€ë‹µí•˜ì„¸ìš”.
    ì†Œì„¤ì— ì—†ëŠ” ë‚´ìš©ì€ ì§€ì–´ë‚´ì§€ ë§ê³ , ìºë¦­í„°ì˜ ë§íˆ¬ì™€ ì„±ê²©ì„ ìœ ì§€í•˜ì„¸ìš”.

    [ì§€ì¹¨]
    1. ë‹µë³€ì€ 2~3ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ í•˜ì„¸ìš”.
    2. ì†Œì„¤ ì† ìƒí™©ì„ ìì—°ìŠ¤ëŸ½ê²Œ ì–¸ê¸‰í•˜ì„¸ìš”.

    [ì°¸ê³ í•œ ì†Œì„¤ ë‚´ìš©]
    {{context}}
    """

    prompt = ChatPromptTemplate.from_messages([
        ("system", system_template),
        MessagesPlaceholder(variable_name="history"), 
        ("human", "{input}"),
    ])

    def format_docs(docs):
        return "\n\n".join([d.page_content for d in docs])

    rag_chain = (
        RunnablePassthrough.assign(
            context=itemgetter("input") | retriever | format_docs
        )
        | prompt
        | llm
        | StrOutputParser()
    )
    return rag_chain


# --- 6. ì„¸ì…˜ ê´€ë¦¬ ---
if "messages" not in st.session_state:
    st.session_state.messages = []

if "store" not in st.session_state:
    st.session_state.store = {}

def get_session_history(session_id: str):
    if session_id not in st.session_state.store:
        st.session_state.store[session_id] = ChatMessageHistory()
    return st.session_state.store[session_id]


# --- 7. ì±„íŒ… UI ---
# ì´ì „ ëŒ€í™” ì¶œë ¥
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
if user_input := st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”..."):
    # 1. ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ
    st.session_state.messages.append({"role": "user", "content": user_input})
    with st.chat_message("user"):
        st.markdown(user_input)

    # 2. API í‚¤ í™•ì¸
    if not os.environ.get("OPENAI_API_KEY"):
        st.error("âš ï¸ ì™¼ìª½ ì‚¬ì´ë“œë°”ì— OpenAI API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        st.stop()

    # 3. AI ì‘ë‹µ ìƒì„±
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        
        # --- [ë””ë²„ê¹… ê¸°ëŠ¥] RAG ê²€ìƒ‰ ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸° ---
        # ì±—ë´‡ì´ ëŒ€ë‹µí•˜ê¸° ì „ì— ë¬´ì—‡ì„ ì½ì—ˆëŠ”ì§€ í™•ì¸
        try:
            retrieved_docs = retriever.invoke(user_input)
            with st.expander(f"ğŸ” '{target_char}'ê°€ ì½ì€ ì†Œì„¤ ë‚´ìš© í™•ì¸í•˜ê¸° (í´ë¦­)"):
                if retrieved_docs:
                    for i, doc in enumerate(retrieved_docs):
                        st.markdown(f"**[ì°¸ê³  {i+1}]**")
                        st.caption(doc.page_content[:300] + "...") # ë„ˆë¬´ ê¸¸ë©´ ìë¦„
                else:
                    st.warning("âš ï¸ ê´€ë ¨ëœ ì†Œì„¤ ë‚´ìš©ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            st.error(f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
        # ---------------------------------------------

        # ì²´ì¸ ì‹¤í–‰
        chain = get_rag_chain()
        chain_with_history = RunnableWithMessageHistory(
            chain,
            get_session_history,
            input_messages_key="input",
            history_messages_key="history",
        )
        
        config = {"configurable": {"session_id": "streamlit_session"}}
        
        with st.spinner(f"{target_char}(ì´)ê°€ ìƒê° ì¤‘..."):
            try:
                response = chain_with_history.invoke(
                    {"input": user_input}, 
                    config=config
                )
                message_placeholder.markdown(response)
                st.session_state.messages.append({"role": "assistant", "content": response})
            except Exception as e:
                st.error(f"ë‹µë³€ ìƒì„± ì˜¤ë¥˜: {e}")
