import streamlit as st
import os

# --- 1. ê¸°ë³¸ ì„¤ì • ---
st.set_page_config(page_title="ì†Œì„¤ ìºë¦­í„° ì±—ë´‡", page_icon="ğŸ“š")
st.title("ğŸ“š ì†Œì„¤ ì† ìºë¦­í„°ì™€ ëŒ€í™”í•˜ê¸°")

# --- 2. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ---
from operator import itemgetter
from langchain_openai import ChatOpenAI
from langchain_community.vectorstores import FAISS
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_community.chat_message_histories import ChatMessageHistory

# --- 3. ì‚¬ì´ë“œë°” ì„¤ì • ---
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")
    
    # API í‚¤ ì…ë ¥
    api_key = st.text_input("OpenAI API Key", type="password")
    if api_key:
        os.environ["OPENAI_API_KEY"] = api_key
    
    # ëª¨ë¸ ì„ íƒ
    # MODEL_NAME = "gpt-3.5-turbo"
    # íŒŒì¸íŠœë‹ëœ ëª¨ë¸ì´ ìˆë‹¤ë©´ ì•„ë˜ ì£¼ì„ì„ í’€ê³  ëª¨ë¸ IDë¥¼ ì ìœ¼ì„¸ìš”
    MODEL_NAME = "gpt-3.5-turbo" 
    
    st.divider()
    
    st.subheader("ğŸ­ ìºë¦­í„° ì„¤ì •")
    target_char = st.text_input("ìºë¦­í„° ì´ë¦„", value="ì…œë¡ í™ˆì¦ˆ")
    user_role = st.text_input("ë‹¹ì‹ ì˜ ì—­í• ", value="ë…ì")
    
    st.divider()
    
    if st.button("ğŸ—‘ï¸ ëŒ€í™” ë‚´ìš© ì´ˆê¸°í™”"):
        st.session_state.messages = []
        st.session_state.store = {}
        st.rerun()

# --- 4. ë°ì´í„°ë² ì´ìŠ¤(FAISS) ë¡œë“œ ---
@st.cache_resource
def load_db():
    DB_PATH = "./novel_db_faiss"
    
    if not os.path.exists(DB_PATH):
        return None
        
    # ì„ë² ë”© ëª¨ë¸ ë¡œë“œ
    embedding_function = HuggingFaceEmbeddings(
        model_name="sentence-transformers/all-MiniLM-L6-v2"
    )
    
    # FAISS DB ë¡œë“œ
    try:
        vectorstore = FAISS.load_local(
            DB_PATH, 
            embedding_function, 
            allow_dangerous_deserialization=True
        )
        return vectorstore.as_retriever(search_kwargs={"k": 3})
    except Exception as e:
        return None

retriever = load_db()

# DB ì˜¤ë¥˜ ì²´í¬
if not retriever:
    st.error("âŒ 'novel_db_faiss' í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
    st.info("í„°ë¯¸ë„ì—ì„œ 'python novel_ingest.py'ë¥¼ ì‹¤í–‰í•˜ì—¬ ì†Œì„¤ì„ ë¨¼ì € ì €ì¥í•´ì£¼ì„¸ìš”.")
    st.stop()

# --- 5. ì²´ì¸ ìƒì„± ---
def get_rag_chain():
    llm = ChatOpenAI(model=MODEL_NAME, temperature=0.7)

    system_template = f"""
    ë‹¹ì‹ ì€ ì†Œì„¤ ì†ì— ë“±ì¥í•˜ëŠ” '{target_char}'ì…ë‹ˆë‹¤.
    í˜„ì¬ ë‹¹ì‹ ì€ '{user_role}'ì™€ ëŒ€í™”í•˜ê³  ìˆìŠµë‹ˆë‹¤.

    ë°˜ë“œì‹œ ì•„ë˜ [ì†Œì„¤ ë‚´ìš©]ì„ ì°¸ê³ í•˜ì—¬ ëŒ€ë‹µí•˜ì„¸ìš”.
    ì†Œì„¤ì— ì—†ëŠ” ë‚´ìš©ì€ ì§€ì–´ë‚´ì§€ ë§ê³ , ëª¨ë¥´ë©´ ëª¨ë¥¸ë‹¤ê³  í•˜ì„¸ìš”.
    
    [ì§€ì¹¨]
    1. ë‹µë³€ì€ 2~3ë¬¸ì¥ ì´ë‚´ë¡œ ê°„ê²°í•˜ê²Œ í•˜ì„¸ìš”.
    2. ì†Œì„¤ ì† ì–´íˆ¬ë¥¼ ìœ ì§€í•˜ì„¸ìš”.

    [ì†Œì„¤ ë‚´ìš©]
    {{context}}
    """

    prompt = ChatPromptTemplate.from_messages([
        ("system", system_template),
        MessagesPlaceholder(variable_name="history"), 
        ("human", "{input}"),
    ])

    def format_docs(docs):
        return "\n\n".join([d.page_content for d in docs])

    rag_chain = (
        RunnablePassthrough.assign(
            context=itemgetter("input") | retriever | format_docs
        )
        | prompt
        | llm
        | StrOutputParser()
    )
    return rag_chain

# --- 6. ì„¸ì…˜ ê´€ë¦¬ ---
if "messages" not in st.session_state:
    st.session_state.messages = []

if "store" not in st.session_state:
    st.session_state.store = {}

def get_session_history(session_id: str):
    if session_id not in st.session_state.store:
        st.session_state.store[session_id] = ChatMessageHistory()
    return st.session_state.store[session_id]

# --- 7. ì±„íŒ… í™”ë©´ êµ¬í˜„ ---

# ì´ì „ ëŒ€í™” ì¶œë ¥
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
if user_input := st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”..."):
    # 1. ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ
    st.session_state.messages.append({"role": "user", "content": user_input})
    with st.chat_message("user"):
        st.markdown(user_input)

    # 2. API í‚¤ í™•ì¸
    if not os.environ.get("OPENAI_API_KEY"):
        st.error("âš ï¸ ì™¼ìª½ ì‚¬ì´ë“œë°”ì— OpenAI API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        st.stop()

    # 3. AI ì‘ë‹µ ìƒì„±
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        
        # --- âœ… [ë””ë²„ê¹… ê¸°ëŠ¥] ì—¬ê¸°ê°€ ì¤‘ìš”í•©ë‹ˆë‹¤! ---
        # ì±—ë´‡ì´ ë‹µë³€í•˜ê¸° ì „ì— ê²€ìƒ‰ëœ ë‚´ìš©ì„ ë¨¼ì € ë³´ì—¬ì¤ë‹ˆë‹¤.
        try:
            retrieved_docs = retriever.invoke(user_input)
            
            with st.expander(f"ğŸ” '{target_char}'ê°€ ì½ì€ ì†Œì„¤ ë‚´ìš© í™•ì¸í•˜ê¸° (í´ë¦­)"):
                if retrieved_docs:
                    for i, doc in enumerate(retrieved_docs):
                        st.markdown(f"**[ì°¸ê³  ë¬¸ë‹¨ {i+1}]**")
                        st.info(doc.page_content) # íŒŒë€ìƒ‰ ë°•ìŠ¤ë¡œ ë‚´ìš© í‘œì‹œ
                else:
                    st.warning("âš ï¸ ê²€ìƒ‰ëœ ì†Œì„¤ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤. (DBê°€ ë¹„ì—ˆê±°ë‚˜ ê´€ë ¨ ë‚´ìš© ì—†ìŒ)")
        except Exception as e:
            st.error(f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        # ----------------------------------------

        # ì²´ì¸ ì‹¤í–‰ ë° ì‘ë‹µ í‘œì‹œ
        chain = get_rag_chain()
        chain_with_history = RunnableWithMessageHistory(
            chain,
            get_session_history,
            input_messages_key="input",
            history_messages_key="history",
        )
        
        config = {"configurable": {"session_id": "streamlit_session"}}
        
        with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
            try:
                response = chain_with_history.invoke(
                    {"input": user_input}, 
                    config=config
                )
                message_placeholder.markdown(response)
                st.session_state.messages.append({"role": "assistant", "content": response})
            except Exception as e:
                st.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
